"""
ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
- Polygon.ioì—ì„œ ì£¼ê°€ + ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
- FinBERT ê°ì„± ë¶„ì„
- LSTM ìž…ë ¥ í˜•íƒœë¡œ ì „ì²˜ë¦¬
- pkl íŒŒì¼ë¡œ ì €ìž¥

ì‹¤í–‰: python prepare_data.py
"""

import hydra
from omegaconf import DictConfig, OmegaConf
import pickle
import os
from src.data_pipeline import PolygonDataPipeline


@hydra.main(version_base=None, config_path="conf", config_name="config")
def main(cfg: DictConfig):
    """
    ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ (í•œ ë²ˆë§Œ ì‹¤í–‰)
    """
    print("=" * 70)
    print("ðŸ“¡ Data Collection & Preprocessing")
    print("=" * 70)
    print(f"ðŸ“Š Ticker: {cfg.data.ticker}")
    print(f"ðŸ“… Period: {cfg.data.start_date} ~ {cfg.data.end_date}")
    print(f"ðŸªŸ Window Size: {cfg.data.window_size}")
    print(f"ðŸ“° News Limit: {cfg.data.news_limit}")
    print("=" * 70)
    
    # API í‚¤ í™•ì¸
    if not cfg.api_key:
        raise ValueError(
            "âŒ POLYGON_API_KEY not found!\n"
            "Please set: set POLYGON_API_KEY=your_key"
        )
    
    # ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = PolygonDataPipeline(cfg)
    X, y, scaler, df_merged = pipeline.prepare_lstm_data()
    
    # ì €ìž¥ íŒŒì¼ëª… ìƒì„±
    output_file = f"data_{cfg.data.ticker}_{cfg.data.start_date}_{cfg.data.end_date}.pkl"
    
    print("\n" + "=" * 70)
    print("ðŸ’¾ Saving Data")
    print("=" * 70)
    
    # ì €ìž¥
    with open(output_file, 'wb') as f:
        pickle.dump({
            'X': X,
            'y': y,
            'scaler': scaler,
            'df_merged': df_merged,
            'config': OmegaConf.to_container(cfg, resolve=True)
        }, f)
    
    print(f"\nâœ… Data saved to: {output_file}")
    print(f"   ðŸ“Š X shape: {X.shape}")
    print(f"   ðŸ“ˆ y shape: {y.shape}")
    print(f"   ðŸ“‹ Features: {X.shape[2]}")
    print(f"   ðŸ“… Samples: {len(X)}")
    
    # í†µê³„ ì •ë³´
    print("\n" + "=" * 70)
    print("ðŸ“Š Data Statistics")
    print("=" * 70)
    
    feature_names = ['Open', 'High', 'Low', 'Close', 'Volume', 'Sentiment_Avg', 'News_Count']
    print(f"   Features ({len(feature_names)}): {', '.join(feature_names)}")
    
    if 'Sentiment_Avg' in df_merged.columns and 'News_Count' in df_merged.columns:
        print(f"\n   ðŸ“° News Statistics:")
        print(f"      - Days with news: {(df_merged['News_Count'] > 0).sum()}")
        print(f"      - Avg sentiment: {df_merged['Sentiment_Avg'].mean():.4f}")
        print(f"      - Avg news/day: {df_merged['News_Count'].mean():.2f}")
    
    print("\n" + "=" * 70)
    print("âœ… Data preparation complete!")
    print(f"   Next step: python train.py")
    print("=" * 70)


if __name__ == "__main__":
    main()
